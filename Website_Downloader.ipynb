{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "0b691407-2f3c-535c-8a3c-cd8925b4ff3a",
        "openai_ephemeral_user_id": "21d1b6bc-d6bf-5fce-9c5a-5250f54c2166",
        "openai_subdivision1_iso_code": "US-WA"
      }
    },
    "noteable": {
      "last_transaction_id": "ed4562c5-4217-40c7-8be3-09cfb287283d"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "05a47a84-465e-4cfa-8723-f153e8eb41c9",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    },
    {
      "id": "e1636b79-6b7c-486d-8075-fbf9880550af",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    },
    {
      "id": "5bf2e79e-cc12-4627-85e0-4a34876e5b11",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "0cf7d783-f0a9-408b-9b41-918147d75773"
        },
        "ExecuteTime": {
          "end_time": "2023-05-28T23:03:41.791872+00:00",
          "start_time": "2023-05-28T23:03:37.024011+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install requests beautifulsoup4",
      "outputs": []
    },
    {
      "id": "0c0a6a04-d754-4d7c-bf44-e26c648ea30a",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "d0f82afc-9db8-49fe-9593-817b1a4d4d32"
        },
        "ExecuteTime": {
          "end_time": "2023-05-28T23:04:08.061906+00:00",
          "start_time": "2023-05-28T23:04:06.969669+00:00"
        }
      },
      "execution_count": null,
      "source": "import os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\n\ndef download_website(url, target_path):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    for link in soup.find_all('link') + soup.find_all('script') + soup.find_all('img'):\n        if 'href' in link.attrs:\n            href = link.attrs['href']\n        elif 'src' in link.attrs:\n            href = link.attrs['src']\n        else:\n            continue\n        target_url = urljoin(url, href)\n        target_file_path = os.path.join(target_path, href.replace('/', '_'))\n        with open(target_file_path, 'wb') as f:\n            f.write(requests.get(target_url).content)\n\ndownload_website('https://florianpichler.de', 'website_files')",
      "outputs": []
    },
    {
      "id": "f5cb4b31-c973-4947-a676-21554f0dc111",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "76fa07a8-4c92-490b-99ae-304ab43aa4d7"
        },
        "ExecuteTime": {
          "end_time": "2023-05-28T23:04:33.851062+00:00",
          "start_time": "2023-05-28T23:04:33.377944+00:00"
        }
      },
      "execution_count": null,
      "source": "def download_website(url, target_path):\n    # Create target directory if it doesn't exist\n    if not os.path.exists(target_path):\n        os.makedirs(target_path)\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    for link in soup.find_all('link') + soup.find_all('script') + soup.find_all('img'):\n        if 'href' in link.attrs:\n            href = link.attrs['href']\n        elif 'src' in link.attrs:\n            href = link.attrs['src']\n        else:\n            continue\n        target_url = urljoin(url, href)\n        target_file_path = os.path.join(target_path, href.replace('/', '_'))\n        with open(target_file_path, 'wb') as f:\n            f.write(requests.get(target_url).content)\n\ndownload_website('https://florianpichler.de', 'website_files')",
      "outputs": []
    }
  ]
}