{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "d5976761-ce22-5287-9b80-6c5c4810ef9d",
        "openai_ephemeral_user_id": "c607f455-92b2-5031-8b5a-c7d089135610",
        "openai_subdivision1_iso_code": "US-CA"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "noteable": {
      "last_transaction_id": "7f3fcd41-420a-46d3-8f6b-35093f86ad24"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "id": "d00d8fbf-d51b-499e-a376-72600b8787db",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "b012d570-2200-4170-b445-63c68c9740ec"
        },
        "ExecuteTime": {
          "end_time": "2023-07-21T23:04:40.494680+00:00",
          "start_time": "2023-07-21T23:04:39.909373+00:00"
        },
        "datalink": {
          "bd0dad8b-72e2-465b-a516-e62cf626fb8b": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 2,
              "orig_num_rows": 5,
              "orig_size_bytes": 120,
              "truncated_num_cols": 2,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 120,
              "truncated_string_columns": []
            },
            "display_id": "bd0dad8b-72e2-465b-a516-e62cf626fb8b",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-07-21T23:04:40.336521",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_e430a726bb8b469ba21e7ada3042be6f"
          }
        }
      },
      "execution_count": null,
      "source": "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom urllib.parse import urljoin\n\ndef get_attorney_general_info(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n    }\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    table = soup.find_all('table')[0]\n    df = pd.read_html(str(table))[0]\n    df.columns = ['District', 'United States Attorney']\n    df['District'] = df['District'].str.replace('\\t', '')\n    df['United States Attorney'] = df['United States Attorney'].str.replace('\\t', '')\n\n    return df\n\nurl = 'https://www.justice.gov/usao/us-attorneys-listing'\ndf = get_attorney_general_info(url)\ndf.head()",
      "outputs": []
    },
    {
      "id": "80adbd27-4260-4410-9a54-1c1d0ee97f32",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "1f355b22-c22b-4997-a4ed-539109be54f0"
        },
        "ExecuteTime": null
      },
      "execution_count": null,
      "source": "def get_phone_number(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n    }\n    response = requests.get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    phone_number = None\n    for p in soup.find_all('p'):\n        if 'Telephone' in p.text:\n            phone_number = p.text.split(':')[1].strip()\n            break\n\n    return phone_number\n\nbase_url = 'https://www.justice.gov/usao/'\ndf['Phone Number'] = df['District'].apply(lambda x: get_phone_number(urljoin(base_url, x.replace(', ', '-').replace(' ', '-').lower())))\ndf.head()",
      "outputs": []
    }
  ]
}